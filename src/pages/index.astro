---
import DocumentationLayout from '../layouts/DocumentationLayout.astro';
import CodeBlock from '../components/CodeBlock.astro';
import InfoBox from '../components/InfoBox.astro';
---

<DocumentationLayout 
  title="Overview" 
  description="Comprehensive documentation for AI-based Face & Emotion Recognition System using Raspberry Pi"
>
  <section class="overview-section">
    <h2>System Overview</h2>
    <p>
      This documentation covers a comprehensive AI-based Face & Emotion Recognition System designed for 
      deployment on Raspberry Pi. The system combines computer vision, deep learning, and real-time 
      processing to detect human faces and classify emotions with high accuracy.
    </p>

    <div class="feature-grid">
      <div class="feature-card">
        <h3>ðŸŽ¯ Real-time Processing</h3>
        <p>Optimized for Raspberry Pi with 15-30 FPS processing capability</p>
      </div>
      <div class="feature-card">
        <h3>ðŸ§  Deep Learning</h3>
        <p>CNN-based emotion classification with 92% accuracy</p>
      </div>
      <div class="feature-card">
        <h3>ðŸ”Œ Easy Integration</h3>
        <p>REST API for seamless integration with existing systems</p>
      </div>
      <div class="feature-card">
        <h3>ðŸ“Š Multi-emotion Detection</h3>
        <p>Supports 7 emotion categories: happy, sad, angry, fear, surprise, disgust, neutral</p>
      </div>
    </div>
  </section>

  <section class="tech-stack">
    <h2>Technology Stack</h2>
    
    <div class="tech-category">
      <h3>Hardware Requirements</h3>
      <ul>
        <li><strong>Raspberry Pi 4B (4GB RAM)</strong> - Main processing unit</li>
        <li><strong>USB Camera (1080p)</strong> - Video input device</li>
        <li><strong>MicroSD Card (32GB Class 10)</strong> - Storage</li>
        <li><strong>Cooling System</strong> - Heat sink and fan for sustained operation</li>
      </ul>
    </div>

    <div class="tech-category">
      <h3>Software Dependencies</h3>
      <ul>
        <li><strong>Python 3.10</strong> - Core programming language</li>
        <li><strong>OpenCV 4.8+</strong> - Computer vision library</li>
        <li><strong>TensorFlow Lite 2.13+</strong> - Deep learning inference</li>
        <li><strong>NumPy, Pandas</strong> - Data processing</li>
        <li><strong>Flask</strong> - Web API framework</li>
      </ul>
    </div>
  </section>

  <section class="quick-start">
    <h2>Quick Start Guide</h2>
    
    <InfoBox type="info" title="Prerequisites">
      Ensure you have a Raspberry Pi 4B with Raspberry Pi OS (64-bit) installed and a compatible USB camera connected.
    </InfoBox>

    <h3>1. Environment Setup</h3>
    <CodeBlock language="bash" title="Initial Setup Commands">
# Update system packages
sudo apt update && sudo apt upgrade -y

# Install Python virtual environment
sudo apt install python3-venv python3-pip -y

# Create project directory
mkdir ~/face-emotion-recognition
cd ~/face-emotion-recognition

# Create virtual environment
python3 -m venv emotion-env
source emotion-env/bin/activate

# Install core dependencies
pip install opencv-python tensorflow-lite numpy pandas flask
    </CodeBlock>

    <h3>2. Basic Implementation</h3>
    <CodeBlock language="python" title="emotion_detector.py">
import cv2
import numpy as np
import tensorflow as tf

class EmotionDetector:
    def __init__(self, model_path):
        # Load pre-trained emotion classification model
        self.interpreter = tf.lite.Interpreter(model_path=model_path)
        self.interpreter.allocate_tensors()
        
        # Emotion labels
        self.emotions = ['angry', 'disgust', 'fear', 'happy', 
                        'neutral', 'sad', 'surprise']
        
        # Face cascade classifier
        self.face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )
    
    def detect_emotion(self, image):
        """Detect faces and classify emotions in real-time"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        faces = self.face_cascade.detectMultiScale(gray, 1.3, 5)
        
        results = []
        for (x, y, w, h) in faces:
            # Extract face region
            face_roi = gray[y:y+h, x:x+w]
            face_roi = cv2.resize(face_roi, (48, 48))
            face_roi = face_roi.astype('float32') / 255.0
            face_roi = np.reshape(face_roi, (1, 48, 48, 1))
            
            # Predict emotion
            input_details = self.interpreter.get_input_details()
            output_details = self.interpreter.get_output_details()
            
            self.interpreter.set_tensor(input_details[0]['index'], face_roi)
            self.interpreter.invoke()
            
            prediction = self.interpreter.get_tensor(output_details[0]['index'])
            emotion_idx = np.argmax(prediction)
            confidence = float(prediction[0][emotion_idx])
            
            results.append({
                'bbox': (x, y, w, h),
                'emotion': self.emotions[emotion_idx],
                'confidence': confidence
            })
        
        return results
    </CodeBlock>

    <InfoBox type="success" title="Expected Performance">
      On Raspberry Pi 4B, expect 15-25 FPS processing speed with 90-95% emotion classification accuracy 
      under good lighting conditions.
    </InfoBox>
  </section>

  <section class="system-architecture-overview">
    <h2>System Architecture Overview</h2>
    <p>
      The system follows a modular architecture designed for scalability and maintainability:
    </p>
    
    <div class="architecture-diagram">
      <div class="arch-layer">
        <h4>Input Layer</h4>
        <p>USB Camera â†’ Video Stream Capture</p>
      </div>
      <div class="arch-arrow">â†“</div>
      <div class="arch-layer">
        <h4>Processing Layer</h4>
        <p>Face Detection â†’ Feature Extraction â†’ Emotion Classification</p>
      </div>
      <div class="arch-arrow">â†“</div>
      <div class="arch-layer">
        <h4>Output Layer</h4>
        <p>Real-time Display â†’ API Endpoints â†’ Data Logging</p>
      </div>
    </div>
  </section>

  <section class="next-steps">
    <h2>Documentation Structure</h2>
    <p>This documentation is organized into the following sections:</p>
    
    <div class="doc-links">
      <a href="/architecture" class="doc-link">
        <h3>System Architecture</h3>
        <p>Detailed system design, data flow, and component interactions</p>
      </a>
      
      <a href="/hardware" class="doc-link">
        <h3>Hardware Setup</h3>
        <p>Complete hardware specifications, assembly, and configuration</p>
      </a>
      
      <a href="/implementation" class="doc-link">
        <h3>Implementation Guide</h3>
        <p>Step-by-step software implementation and model training</p>
      </a>
      
      <a href="/performance" class="doc-link">
        <h3>Performance & Testing</h3>
        <p>Benchmarks, optimization techniques, and testing methodologies</p>
      </a>
      
      <a href="/integration" class="doc-link">
        <h3>API & Integration</h3>
        <p>REST API documentation and integration examples</p>
      </a>
      
      <a href="/troubleshooting" class="doc-link">
        <h3>Troubleshooting</h3>
        <p>Common issues, solutions, and debugging guidelines</p>
      </a>
    </div>
  </section>
</DocumentationLayout>

<style>
  .overview-section {
    margin-bottom: 3rem;
  }

  .overview-section h2 {
    color: #111827;
    font-size: 1.875rem;
    font-weight: 600;
    margin-bottom: 1rem;
  }

  .overview-section p {
    font-size: 1.125rem;
    color: #4b5563;
    margin-bottom: 2rem;
  }

  .feature-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
    gap: 1.5rem;
    margin: 2rem 0;
  }

  .feature-card {
    background: white;
    padding: 1.5rem;
    border-radius: 0.75rem;
    border: 1px solid #e5e7eb;
    box-shadow: 0 1px 3px 0 rgb(0 0 0 / 0.1);
    transition: transform 0.2s ease;
  }

  .feature-card:hover {
    transform: translateY(-2px);
    box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1);
  }

  .feature-card h3 {
    font-size: 1.125rem;
    font-weight: 600;
    color: #111827;
    margin-bottom: 0.5rem;
  }

  .feature-card p {
    color: #6b7280;
    font-size: 0.875rem;
  }

  .tech-stack {
    margin: 3rem 0;
  }

  .tech-stack h2 {
    color: #111827;
    font-size: 1.875rem;
    font-weight: 600;
    margin-bottom: 2rem;
  }

  .tech-category {
    margin-bottom: 2rem;
  }

  .tech-category h3 {
    color: #374151;
    font-size: 1.25rem;
    font-weight: 600;
    margin-bottom: 1rem;
  }

  .tech-category ul {
    list-style: none;
    padding: 0;
  }

  .tech-category li {
    padding: 0.5rem 0;
    border-bottom: 1px solid #f3f4f6;
    color: #4b5563;
  }

  .tech-category li:last-child {
    border-bottom: none;
  }

  .tech-category strong {
    color: #111827;
  }

  .quick-start {
    margin: 3rem 0;
  }

  .quick-start h2, .quick-start h3 {
    color: #111827;
    margin-bottom: 1rem;
  }

  .quick-start h2 {
    font-size: 1.875rem;
    font-weight: 600;
  }

  .quick-start h3 {
    font-size: 1.25rem;
    font-weight: 600;
    margin-top: 2rem;
  }

  .system-architecture-overview {
    margin: 3rem 0;
  }

  .system-architecture-overview h2 {
    color: #111827;
    font-size: 1.875rem;
    font-weight: 600;
    margin-bottom: 1rem;
  }

  .architecture-diagram {
    display: flex;
    flex-direction: column;
    align-items: center;
    margin: 2rem 0;
    padding: 2rem;
    background: white;
    border-radius: 0.75rem;
    border: 1px solid #e5e7eb;
  }

  .arch-layer {
    background: #f8fafc;
    border: 2px solid #3b82f6;
    border-radius: 0.75rem;
    padding: 1.5rem;
    text-align: center;
    min-width: 300px;
  }

  .arch-layer h4 {
    color: #3b82f6;
    font-weight: 600;
    margin-bottom: 0.5rem;
  }

  .arch-layer p {
    color: #4b5563;
    font-size: 0.875rem;
  }

  .arch-arrow {
    font-size: 1.5rem;
    color: #3b82f6;
    margin: 1rem 0;
  }

  .next-steps {
    margin: 3rem 0;
  }

  .next-steps h2 {
    color: #111827;
    font-size: 1.875rem;
    font-weight: 600;
    margin-bottom: 1rem;
  }

  .doc-links {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
    gap: 1.5rem;
    margin-top: 2rem;
  }

  .doc-link {
    display: block;
    background: white;
    padding: 1.5rem;
    border-radius: 0.75rem;
    border: 1px solid #e5e7eb;
    text-decoration: none;
    transition: all 0.2s ease;
  }

  .doc-link:hover {
    border-color: #3b82f6;
    box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1);
  }

  .doc-link h3 {
    color: #111827;
    font-size: 1.125rem;
    font-weight: 600;
    margin-bottom: 0.5rem;
  }

  .doc-link p {
    color: #6b7280;
    font-size: 0.875rem;
    margin: 0;
  }

  @media (max-width: 768px) {
    .feature-grid {
      grid-template-columns: 1fr;
    }

    .doc-links {
      grid-template-columns: 1fr;
    }

    .architecture-diagram {
      padding: 1rem;
    }

    .arch-layer {
      min-width: 250px;
    }
  }
</style>